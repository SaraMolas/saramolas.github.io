# Various research projects I've worked on over the years

## [Applying SAEs to biological neurons](https://openreview.net/pdf?id=cPpMl7Y2y3)

NeurIPS 2025 – Data on the Brain & Mind Workshop

We introduced NLDisco, a sparse autoencoder-based pipeline to uncover interpretable latent structure in high-dimensional neural recordings. This approach encourages latent units to align with meaningful features in the data, making it easier to link neural activity to behavior or experimental variables. Across synthetic and real datasets, NLDisco recovers clearer, more interpretable latent features than many traditional embedding methods.

## [Compressed computation is not computation in superposition](https://openreview.net/pdf?id=iVeOIeHDP1)

NeurIPS 2025 - Mechanistic Interpretability Workshop

When we benchmark models, performance alone doesn’t guarantee we understand how they compute. We need mechanistic clarity so that interpretations reflect real internal structure, not artifacts. We analyzed a benchmark toy model of Compressed Computation previously thought to implement many functions via superposition, decomposing its training objective into computation and noise-induced mixing components. The model’s apparent advantage comes from a noise-driven mixing effect, not true superposition; when the mixing term is removed, performance drops and a simple baseline based on the mixing term reproduces the behavior.

## Attention affects the brain's GPS

## GPS neurons that distinguish identical rooms

## Biological neurons that count rooms




[← Back to home](/)
